{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score mouse regions in human sc data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore','invalid value encountered in true_divide')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import anndata as ad\n",
    "import scipy\n",
    "\n",
    "import scanpy as sc\n",
    "import tacco as tc\n",
    "\n",
    "from matplotlib.colors import LinearSegmentedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "# Make helper functions available: The notebook expects to be executed either in the sub-workflow directory or in the notebooks directory\n",
    "sys.path.insert(1, '../'), sys.path.insert(1, '../workflow/'); # prefer to look just one directory up\n",
    "import helper\n",
    "sys.path.pop(1), sys.path.pop(1);\n",
    "\n",
    "get_path = helper.get_paths('human_sc')\n",
    "figures_folder = get_path('plots')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analysis settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "enrichment_method = {'reduction':'sum','normalization':'clr','method':'welch','assume_counts':True,}\n",
    "p_key = f'p_{enrichment_method[\"method\"]}_fdr_bh'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and convert the human data into mouse gene space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mouse_scrna = ad.read(f'{get_path(\"resources\",\"mouse_sc\")}/scRNAseq.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mouse_pucks = ad.read(f'{get_path(\"resources\",\"mouse_slideseq\")}/slideseq.h5ad')\n",
    "mouse_pucks_by_compartment = ad.read(f'{get_path(\"resources\",\"mouse_slideseq\")}/slideseq_by_compartment.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pelka = ad.read(f'{get_path(\"data\")}/Pelka.h5ad')\n",
    "pelka = pelka[pelka.obs['PROCESSING_TYPE'].isin(['unsorted'])].copy() # subset to \"unbiased\" cell sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tc.tl.setup_orthology_converter(f'{get_path(\"resources\")}/MGI/HOM_MouseHumanSequence.rpt');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pelka2mouse = tc.tl.run_orthology_converter(pelka, 'human', 'mouse', mouse_scrna.var.index, use_synonyms=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use only data from sufficiently covered beads\n",
    "mouse_pucks = mouse_pucks[mouse_pucks.X.sum(axis=1)>=100].copy()\n",
    "mouse_pucks_by_compartment = mouse_pucks_by_compartment[mouse_pucks_by_compartment.obs['index'].isin(mouse_pucks.obs.index)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prepare spatial sample split\n",
    "tc.utils.split_spatial_samples(mouse_pucks, buffer_thickness=400, split_scheme=(2,2), sample_key='SampleID', result_key='SampleID_split', check_splits=False)\n",
    "mouse_pucks_by_compartment.obs['SampleID_split'] = mouse_pucks_by_compartment.obs['index'].map(mouse_pucks.obs['SampleID_split'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compare TNK composition between human and mouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tnk_mouse = mouse_scrna[mouse_scrna.obs['labels'].isin(['TNK'])].copy()\n",
    "tnkilc_human = pelka2mouse[pelka2mouse.obs['clTopLevel'].isin(['TNKILC'])].copy()\n",
    "tc.tl.annotate(tnk_mouse, tnkilc_human, 'cl295v11SubFull', result_key='cl295v11SubFull', method='OT', assume_valid_counts=True,bisections=4,max_annotation=1,verbose=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tnkilc_human.obs['cl295v11SubFull'] = tnkilc_human.obs['cl295v11SubFull'].astype('category')\n",
    "\n",
    "clr_human_contr = tc.tl.get_contributions(tnkilc_human,'cl295v11SubFull','TMMR',sample_key='PID',reduction='sum',normalization='sum', reads=False, assume_counts=True)\n",
    "\n",
    "clr_mouse_contr = tc.tl.get_contributions(tnk_mouse,'cl295v11SubFull','State',sample_key='SampleID',reduction='sum',normalization='sum', reads=False, assume_counts=True)\n",
    "\n",
    "clr_contr = pd.concat({'mouse':clr_mouse_contr,'human':clr_human_contr,})\n",
    "\n",
    "clr_contr_ad = ad.AnnData(clr_contr.to_numpy(),)\n",
    "\n",
    "clr_contr_ad.obs['species'] = clr_contr.index.get_level_values(level=0).astype('category')\n",
    "clr_contr_ad.obs['State'] = clr_contr.index.get_level_values(level=1).astype('category')\n",
    "tc.utils.merge_annotation(clr_contr_ad, 'State', {'dysplastic':['premalignant','malignant (3weeks)','malignant (9weeks)']}, result_key='cState')\n",
    "clr_contr_ad.obs['State'] = (clr_contr_ad.obs['cState'].astype(str) + ' (' + clr_contr_ad.obs['species'].astype(str) + ')').astype('category')\n",
    "\n",
    "sc.pp.neighbors(clr_contr_ad)\n",
    "\n",
    "sc.tl.umap(clr_contr_ad)\n",
    "\n",
    "fig = tc.pl.scatter(clr_contr_ad,keys=['State',],position_key='X_umap',point_size=20,axsize=0.3,joint=True,margin=0.1,axes_labels=['UMAP1','UMAP2'], padding=0.7, noticks=False);\n",
    "fig.get_axes()[0].set_title('embedding samples wrt. TNK compositions');\n",
    "\n",
    "fig.savefig(f'{figures_folder}/human_sc_tnk_composition_umap.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_distance = 2\n",
    "n_permutation = 100\n",
    "\n",
    "what = 'State'\n",
    "center = 'State'\n",
    "\n",
    "analysis_key=f'{what}-{center}'\n",
    "tc.tl.co_occurrence_matrix(adata=clr_contr_ad, annotation_key=what, center_key=center,\n",
    "    distance_key=None, position_key='X_umap', max_distance=max_distance, sparse=False,\n",
    "    result_key=analysis_key, verbose=0,\n",
    "    n_permutation=n_permutation,reads=False,\n",
    ")\n",
    "\n",
    "fig = tc.pl.co_occurrence_matrix({'':clr_contr_ad}, score_key='z', cmap_vmin_vmax=(-5,5), cmap='bwr', analysis_key=analysis_key, y_padding=3.5,axsize=(2,2),);\n",
    "\n",
    "fig.get_axes()[0].set_title('z-score on neighbourships in TNK composition UMAP');\n",
    "\n",
    "fig.savefig(f'{figures_folder}/human_sc_tnk_composition_occ.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Epithelial program similarity between human and mouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for program_name, filename in [('pEpi','EpiTGlobalv5ForceK43'),('pEpiTp','EpiTMSSv4ForceK32'),('pEpiTd','EpiTMSIv4ForceK29')]:\n",
    "    program_file = f'{get_path(\"resources\")}/Pelka/ccNMF_GeneWeight_Wmat/ccNMF_RawWeights_{filename}.csv.gz'\n",
    "    \n",
    "    weights = pd.read_csv(program_file, index_col=0)\n",
    "    weights = weights.loc[weights.select_dtypes(include=np.number).sum(axis=1)>0]\n",
    "    weights = weights.loc[weights.index.value_counts()[weights.index.value_counts() == 1].index]\n",
    "    \n",
    "    ## Translate human programs to mouse genes\n",
    "    pr2m = tc.tl.run_orthology_converter(ad.AnnData(weights.T, dtype=np.float32), 'human', 'mouse', mouse_scrna.var.index, use_synonyms=True)\n",
    "    rhp = pd.DataFrame(pr2m.X.T, index=pr2m.var.index, columns=pr2m.obs.index)\n",
    "\n",
    "    pelka2mouse_sub = pelka2mouse.query(f'compartment==\"epithelial\"')\n",
    "    ref_sub = mouse_scrna.query(f'compartment==\"epithelial\"')\n",
    "\n",
    "    min_counts=100\n",
    "    (pelka2mouse_sub,ref_sub,) = tc.pp.filter((pelka2mouse_sub,ref_sub,),min_counts_per_gene=min_counts,assume_valid_counts=True,)\n",
    "    rmp = ref_sub.varm['Epithelial_programs'].loc[~ref_sub.varm['Epithelial_programs'].isna().any(axis=1)]\n",
    "    good_genes = rmp.index.intersection(rhp.index)\n",
    "    pelka2mouse_sub = pelka2mouse_sub[:,good_genes]\n",
    "    ref_sub = ref_sub[:,good_genes]\n",
    "    rhp = rhp.loc[good_genes].copy()\n",
    "    rmp = rmp.loc[good_genes].copy()\n",
    "    rhp /= (rhp.sum(axis=0).to_numpy() / 1e4)\n",
    "    rmp /= (rmp.sum(axis=0).to_numpy() / 1e4)\n",
    "    rhp = np.log1p(rhp)\n",
    "    rmp = np.log1p(rmp)\n",
    "\n",
    "    background = tc.sum(ref_sub.X,axis=0)\n",
    "    background /= background.sum() / 1e4\n",
    "    background = np.log1p(background)\n",
    "    rmp -= background[:,None]\n",
    "    background = tc.sum(pelka2mouse_sub.X,axis=0)\n",
    "    background /= background.sum() / 1e4\n",
    "    background = np.log1p(background)\n",
    "    rhp -= background[:,None]\n",
    "\n",
    "    concated = pd.concat([rhp,rmp],axis=1)\n",
    "    s_corr = 1-tc.utils.cdist(concated.T,metric=\"correlation\")[rhp.shape[1]:,:rhp.shape[1]]\n",
    "    s_corr = pd.DataFrame(s_corr, index=rmp.columns, columns=rhp.columns)\n",
    "    s_corr = s_corr.loc[(s_corr>0.4).any(axis=1),(s_corr>0.4).any(axis=0)]\n",
    "    n_corr = s_corr / s_corr.max(axis=0).to_numpy()\n",
    "\n",
    "    cmap_br = LinearSegmentedColormap.from_list('cmap_br', ['#4d85b5', '#ffffff', '#ff1217'])\n",
    "    fig,axs = tc.pl.subplots(axsize=[0.25*s_corr.shape[0],0.25*s_corr.shape[1]])\n",
    "    tc.pl.heatmap(s_corr,None,None,cmap=cmap_br,cmap_center=None, ax=axs[0,0], value_order='diag', group_labels_rotation=45);\n",
    "    axs[0,0].set_title(f'correlation between human and mouse programs')\n",
    "    fig.savefig(f'{figures_folder}/human_sc_{program_name}_similarity_with_mouse_epi_programs.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# human program associations across human and mouse samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "program_specs = pd.DataFrame(np.array([\n",
    "    ['pEpiTd',f'labels==\"Epi\"',f'clTopLevel==\"Epi\"','EpiTMSIv4ForceK29'],\n",
    "    ['pEpiTp',f'labels==\"Epi\"',f'clTopLevel==\"Epi\"','EpiTMSSv4ForceK32'],\n",
    "    ['pTNI',f'labels==\"TNK\"',f'clTopLevel==\"TNKILC\"','T'],\n",
    "    ['pM',f'labels==\"Mono\" | labels==\"Mac\"',f'clTopLevel==\"Myeloid\"','Myeloid'],\n",
    "]),columns=['program_name','selector_mouse','selector_human','filename']).set_index('program_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prog_maps_mouse = {}\n",
    "prog_maps_human = {}\n",
    "for program_name in program_specs.index:\n",
    "    print(program_name)\n",
    "    selector_mouse = program_specs.loc[program_name,'selector_mouse']\n",
    "    selector_human = program_specs.loc[program_name,'selector_human']\n",
    "    filename = program_specs.loc[program_name,'filename']\n",
    "    \n",
    "    program_file = f'{get_path(\"resources\")}/Pelka/ccNMF_GeneWeight_Wmat/ccNMF_RawWeights_{filename}.csv.gz'\n",
    "    \n",
    "    weights = pd.read_csv(program_file, index_col=0)\n",
    "    weights = weights.loc[weights.select_dtypes(include=np.number).sum(axis=1)>0]\n",
    "    weights = weights.loc[weights.index.value_counts()[weights.index.value_counts() == 1].index]\n",
    "    \n",
    "    ## Translate human programs to mouse genes\n",
    "    pr2m = tc.tl.run_orthology_converter(ad.AnnData(weights.T, dtype=np.float32), 'human', 'mouse', mouse_scrna.var.index, use_synonyms=True)\n",
    "    rhp = pd.DataFrame(pr2m.X.T, index=pr2m.var.index, columns=pr2m.obs.index)\n",
    "\n",
    "    pelka2mouse_sub = pelka2mouse.query(selector_human).copy()\n",
    "    ref_sub = mouse_scrna.query(selector_mouse)\n",
    "\n",
    "    pelka2mouse_sub.varm[program_name] = rhp\n",
    "    \n",
    "    prog_names = pelka2mouse_sub.varm[program_name].columns\n",
    "    n_progs = len(prog_names)\n",
    "    # use flat prior\n",
    "    annotation_prior=pd.Series(np.full(n_progs,1/n_progs),index=prog_names)\n",
    "    \n",
    "    prog_maps_mouse[program_name] = tc.tl.annotate(ref_sub, pelka2mouse_sub, program_name, method='OT', assume_valid_counts=True,bisections=4,min_counts_per_cell=50,verbose=0, annotation_prior=annotation_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prog_comps_mouse = {}\n",
    "for prog_name, prog_map in prog_maps_mouse.items():\n",
    "    mouse_scrna.obsm[prog_name] = prog_map.reindex(mouse_scrna.obs.index)\n",
    "    prog_comps_mouse[prog_name] = tc.tl.get_contributions(mouse_scrna.query('State != \"normal\"'),prog_name,'SampleID',reads=False, normalization='clr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prog_comps_mouse = pd.concat(prog_comps_mouse.values(), axis=1, )\n",
    "all_prog_comps = {'mouse_not_normal':prog_comps_mouse,}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# region-related analysis across human and mouse samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "compartment_pelka2mouse = { comp: pelka2mouse[df.index].copy() for comp, df in pelka2mouse.obs.groupby('compartment') }\n",
    "## Get spatial data\n",
    "compartment_pucks = { comp: mouse_pucks_by_compartment[df.index].copy() for comp, df in mouse_pucks_by_compartment.obs.groupby('compartment') }\n",
    "## Get mouse reference\n",
    "compartment_refs = { comp: mouse_scrna[df.index].copy() for comp, df in mouse_scrna.obs.groupby('compartment') }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##### Transfer region annotation\n",
    "kw_args = {\n",
    "    'method':'OT',\n",
    "    'annotation_key':'region',\n",
    "    'result_key':'region_anno',\n",
    "    'verbose':0,\n",
    "    'multi_center': 10,\n",
    "    'bisections': 7,\n",
    "    'assume_valid_counts': True,\n",
    "}\n",
    "for c in compartment_pucks.keys():\n",
    "    %time tc.tl.annotate(compartment_pucks[c], compartment_pucks[c], **kw_args, ); # validation within pucks\n",
    "    %time tc.tl.annotate(compartment_pelka2mouse[c], compartment_pucks[c], **kw_args, );\n",
    "    %time tc.tl.annotate(compartment_refs[c], compartment_pucks[c], **kw_args, );\n",
    "##### Write results\n",
    "for label,datasets in zip(['pucks','reference','human'],[compartment_pucks,compartment_refs,compartment_pelka2mouse]):\n",
    "    for c in compartment_pucks.keys():\n",
    "        datasets[c].obsm['region_anno'].to_csv(f'{figures_folder}/{label}_region_anno_{c}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read per compartment region annotation\n",
    "for label,datasets in zip(['pucks','reference','human'],[compartment_pucks,compartment_refs,compartment_pelka2mouse]):\n",
    "    if label == 'human':\n",
    "        continue\n",
    "    for c in compartment_pucks.keys():\n",
    "        df = pd.read_csv(f'{figures_folder}/{label}_region_anno_{c}.csv')\n",
    "        datasets[c].obsm['region_anno'] = df.set_index(df.columns[0])\n",
    "# organize data\n",
    "specs = pd.DataFrame([[{},{},{},{}],['region','region_anno','region_anno','region_anno',],['SampleID_split','SampleID_split','SampleID','PatientTypeID'],['State','State','State','TMMR']],index=['datasets','region_key','sample_key','anno_key'],columns=['pucks','mapped','mouse','human']).T\n",
    "for k in compartment_pucks.keys():\n",
    "    specs.loc['pucks','datasets'][k] = compartment_pucks[k]\n",
    "    specs.loc['mapped','datasets'][k] = compartment_pucks[k]\n",
    "    specs.loc['mouse','datasets'][k] = compartment_refs[k]\n",
    "    specs.loc['human','datasets'][k] = compartment_pelka2mouse[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def define_region_ordering(enrichments):\n",
    "    ### sort regions according to median signed log significance\n",
    "    enr_e = pd.pivot(enrichments[enrichments['enrichment']=='enriched'], 'region', 'State', p_key)\n",
    "    enr_p = pd.pivot(enrichments[enrichments['enrichment']!='enriched'], 'region', 'State', p_key)\n",
    "    small_value = 1e-300\n",
    "    enr_e = np.maximum(enr_e,small_value)\n",
    "    enr_p = np.maximum(enr_p,small_value)\n",
    "    enr_p = enr_p.reindex_like(enr_e)\n",
    "    enr = pd.DataFrame(np.where(enr_e < enr_p, -np.log(enr_e), np.log(enr_p)),index=enr_e.index,columns=enr_e.columns)\n",
    "    return enr[enr.columns[enr.columns.str.startswith('normal')]].median(axis=1).sort_values().index.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_labels = ['human']\n",
    "regions_dtype = specs.loc['pucks','datasets']['epithelial'].obs[specs.loc['pucks','region_key']].dtype\n",
    "regions_dtype = pd.CategoricalDtype(categories=regions_dtype.categories, ordered=True)\n",
    "for label in selected_labels:\n",
    "    enrichments = []\n",
    "    for compartment in compartment_pucks.keys():\n",
    "\n",
    "        dataset = specs.loc[label,'datasets'][compartment]\n",
    "        region_key = specs.loc[label,'region_key']\n",
    "        sample_key = specs.loc[label,'sample_key']\n",
    "        anno_key = specs.loc[label,'anno_key']\n",
    "\n",
    "        dataset_enrichments = tc.tl.enrichments(dataset,region_key,anno_key,sample_key=sample_key,**enrichment_method,reference_group='normal',reads=True,)\n",
    "\n",
    "        dataset_enrichments['State'] = dataset_enrichments[anno_key].map(lambda x: f'{x} ({compartment})')\n",
    "        dataset_enrichments['region'] = dataset_enrichments[region_key]\n",
    "        \n",
    "        enrichments.append(dataset_enrichments)\n",
    "\n",
    "    enrichments = pd.concat(enrichments)\n",
    "    enrichments['State'] = enrichments['State'].astype(pd.CategoricalDtype(categories=sorted(enrichments['State'].unique()), ordered=True))\n",
    "    enrichments['region'] = enrichments['region'].astype(pd.CategoricalDtype(define_region_ordering(enrichments), ordered=True))\n",
    "    \n",
    "    \n",
    "    for annotate_pvalues in [False]:\n",
    "        fig = tc.pl.significances(enrichments, p_key, 'region', 'State', annotate_pvalues=annotate_pvalues, value_cluster=False);\n",
    "        \n",
    "        fig.savefig(f'{figures_folder}/human_sc_enrichment_region_vs_State_per_compartment_{label}{\"\" if annotate_pvalues else \"_plain\"}.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_labels = ['pucks','mapped','mouse','human']\n",
    "for compartment in compartment_pucks.keys():\n",
    "    enrichments = []\n",
    "    for label in selected_labels:\n",
    "\n",
    "        dataset = specs.loc[label,'datasets'][compartment]\n",
    "        region_key = specs.loc[label,'region_key']\n",
    "        sample_key = specs.loc[label,'sample_key']\n",
    "        anno_key = specs.loc[label,'anno_key']\n",
    "\n",
    "        dataset_enrichments = tc.tl.enrichments(dataset,region_key,anno_key,sample_key=sample_key,**enrichment_method,reference_group='normal',reads=True)\n",
    "\n",
    "        dataset_enrichments['State'] = dataset_enrichments[anno_key].map(lambda x: f'{x} ({label})')\n",
    "        dataset_enrichments['region'] = dataset_enrichments[region_key]\n",
    "        \n",
    "        enrichments.append(dataset_enrichments)\n",
    "\n",
    "    enrichments = pd.concat(enrichments)\n",
    "    enrichments['State'] = enrichments['State'].astype(pd.CategoricalDtype(categories=[ 'normal VS rest (pucks)', 'normal VS rest (mapped)', 'normal VS rest (mouse)', 'normal VS rest (human)', 'premalignant VS normal (pucks)', 'premalignant VS normal (mapped)', 'premalignant VS normal (mouse)', 'malignant (3weeks) VS normal (mouse)', 'malignant (9weeks) VS normal (mouse)', 'MMRd VS normal (human)', 'MMRp VS normal (human)', ], ordered=True))\n",
    "    enrichments['region'] = enrichments['region'].astype(pd.CategoricalDtype(define_region_ordering(enrichments), ordered=True))\n",
    "\n",
    "    for annotate_pvalues in [False]:\n",
    "        fig = tc.pl.significances(enrichments, p_key, 'region', 'State', annotate_pvalues=annotate_pvalues, value_cluster=False);\n",
    "    \n",
    "        fig.savefig(f'{figures_folder}/human_sc_enrichment_region_vs_State_per_dataset_{compartment}{\"\" if annotate_pvalues else \"_plain\"}.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epi_mouse = mouse_scrna[mouse_scrna.obs['labels'].isin(['Epi'])]\n",
    "epi_human = pelka2mouse[pelka2mouse.obs['clTopLevel'].isin(['Epi'])].copy()\n",
    "tc.tl.annotate(epi_human, epi_mouse, 'Epithelial_programs', result_key='Epithelial_programs', method='OT', bisections=4, assume_valid_counts=True,verbose=0);\n",
    "\n",
    "human_enrichments = tc.tl.enrichments(epi_human,'Epithelial_programs','TMMR',sample_key='PID',**enrichment_method,reads=True,)\n",
    "mouse_enrichments = tc.tl.enrichments(epi_mouse,'Epithelial_programs','State',sample_key='SampleID',**enrichment_method,reads=True,)\n",
    "human_enrichments['State'] = human_enrichments['TMMR'].map(lambda x: f'{x} (human)')\n",
    "mouse_enrichments['State'] = mouse_enrichments['State'].map(lambda x: f'{x} (mouse)')\n",
    "enrichments = pd.concat([mouse_enrichments,human_enrichments])\n",
    "state_order = [f'normal (human)',f'normal (mouse)']\n",
    "for state in human_enrichments['State'].cat.categories:\n",
    "    if state != 'normal (human)':\n",
    "        state_order.append(f'{state}')\n",
    "for state in mouse_enrichments['State'].cat.categories:\n",
    "    if state != 'normal (mouse)':\n",
    "        state_order.append(f'{state}')\n",
    "enrichments['State'] = enrichments['State'].astype(pd.CategoricalDtype(categories=state_order, ordered=True))\n",
    "\n",
    "sorting_enr = enrichments.query(f'State==\"normal (mouse)\"&enrichment==\"enriched\"').set_index('Epithelial_programs')[p_key]\n",
    "sorting_dep = enrichments.query(f'State==\"normal (mouse)\"&enrichment!=\"enriched\"').set_index('Epithelial_programs')[p_key]\n",
    "program_order = pd.DataFrame({'enr':sorting_enr,'dep':sorting_dep}).sort_values(['enr','dep'],ascending=[True,False]).index.to_numpy()\n",
    "enrichments['Epithelial_programs'] = enrichments['Epithelial_programs'].astype(pd.CategoricalDtype(categories=program_order, ordered=True))\n",
    "\n",
    "fig = tc.pl.significances(enrichments, p_key, 'Epithelial_programs', 'State');\n",
    "fig.savefig(f'{figures_folder}/human_sc_enrichment_epithelial_programs_vs_State_per_species.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cell-type associations across samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_mouse = mouse_scrna\n",
    "all_human = pelka2mouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tc.tl.annotate(all_human, all_mouse, 'cluster', result_key='cluster1e-3', method='OT', bisections=4, assume_valid_counts=True,verbose=1, lamb=1e-3);\n",
    "tc.utils.merge_annotation(all_human, annotation_key='cluster1e-3', result_key='labels1e-3', mapping=all_mouse.obs[['cluster','labels']].drop_duplicates().groupby('labels')['cluster'].agg(lambda x: list(x.to_numpy())));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for annoext in ['']:\n",
    "    tc.utils.merge_annotation(all_human, annotation_key=f'labels1e-3{annoext}', result_key=f'mouseL{annoext}', mapping={\n",
    "    });\n",
    "    tc.utils.get_maximum_annotation(all_human, f'mouseL{annoext}', f'mouseL{annoext}_cat');\n",
    "tc.utils.merge_annotation(all_human, annotation_key='clMidwayPr', result_key='humanL', mapping={\n",
    "    'B': ['B','Plasma'],\n",
    "    'TNK': ['TCD4', 'NK', 'TCD8', 'TZBTB16', 'Tgd', 'ILC'],\n",
    "    'Mono':['Mono', 'DC',],\n",
    "    'Mac':['Macro'],\n",
    "    'Gran':['Granulo'],\n",
    "    'Endo':['Endo'],\n",
    "    'Fibro':['Fibro','Peri','SmoothMuscle', 'Schwann'],\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "cmap_br = matplotlib.colors.LinearSegmentedColormap.from_list('cmap_br', ['#4d85b5', '#ffffff', '#ff1217'])\n",
    "\n",
    "if not hasattr(all_human.obs['humanL'], 'cat'):\n",
    "    all_human.obs['humanL'] = all_human.obs['humanL'].astype('category')\n",
    "good_labels = ['Epi','B','TNK','Mono','Mac','Gran','Mast','Endo','Fibro']\n",
    "\n",
    "def compost(sub, norm, reads, labels, sample):\n",
    "    cont = norm == 'clr'\n",
    "    reads = reads == 'reads'\n",
    "    if (not cont) and reads:\n",
    "        return tc.tl.get_compositions(sub,labels,sample,reads=True)\n",
    "    elif (not cont) and not reads:\n",
    "        return tc.tl.get_compositions(sub,labels,sample,reads=False)\n",
    "    elif cont and reads:\n",
    "        return tc.tl.get_contributions(sub,labels,sample,reads=True, normalization='clr')\n",
    "    elif cont and not reads:\n",
    "        return tc.tl.get_contributions(sub,labels,sample,reads=False, normalization='clr')\n",
    "    else:\n",
    "        raise ValueError()\n",
    "\n",
    "clustered = False\n",
    "for norm in ['clr']:\n",
    "    for reads in ['cells']:\n",
    "\n",
    "        fig,axs = tc.pl.subplots(5,2,axsize=[0.3*len(good_labels),0.3*len(good_labels)],x_padding=1.5,y_padding=1)\n",
    "\n",
    "        value_cluster,group_cluster=clustered,clustered\n",
    "\n",
    "        for anno_i,anno in enumerate(['humanL',]):\n",
    "\n",
    "            axs[anno_i,0].set_title(f'all: {anno}')\n",
    "            comps = compost(pelka2mouse, norm=norm, reads=reads, labels=anno, sample='PID')\n",
    "            corr = 1-tc.utils.cdist(comps.T,metric=\"correlation\")\n",
    "            corr = pd.DataFrame(corr, index=comps.columns, columns=comps.columns)\n",
    "            corr = corr.loc[good_labels,good_labels]\n",
    "            tc.pl.heatmap(corr,None,None,cmap=cmap_br,cmap_center=0, ax=axs[anno_i,0], value_cluster=value_cluster, group_cluster=group_cluster);\n",
    "\n",
    "            axs[anno_i,1].set_title(f'normal: {anno}')\n",
    "            comps = compost(pelka2mouse.query('TMMR == \"normal\"'), norm=norm, reads=reads, labels=anno, sample='PID')\n",
    "            corr = 1-tc.utils.cdist(comps.T,metric=\"correlation\")\n",
    "            corr = pd.DataFrame(corr, index=comps.columns, columns=comps.columns)\n",
    "            corr = corr.loc[good_labels,good_labels]\n",
    "            tc.pl.heatmap(corr,None,None,cmap=cmap_br,cmap_center=0, ax=axs[anno_i,1], value_cluster=value_cluster, group_cluster=group_cluster);\n",
    "\n",
    "            axs[anno_i,2].set_title(f'not-normal: {anno}')\n",
    "            comps = compost(pelka2mouse.query('TMMR != \"normal\"'), norm=norm, reads=reads, labels=anno, sample='PID')\n",
    "            corr = 1-tc.utils.cdist(comps.T,metric=\"correlation\")\n",
    "            corr = pd.DataFrame(corr, index=comps.columns, columns=comps.columns)\n",
    "            corr = corr.loc[good_labels,good_labels]\n",
    "            tc.pl.heatmap(corr,None,None,cmap=cmap_br,cmap_center=0, ax=axs[anno_i,2], value_cluster=value_cluster, group_cluster=group_cluster);\n",
    "\n",
    "            axs[anno_i,3].set_title(f'MMRd: {anno}')\n",
    "            comps = compost(pelka2mouse.query('TMMR == \"MMRd\"'), norm=norm, reads=reads, labels=anno, sample='PID')\n",
    "            corr = 1-tc.utils.cdist(comps.T,metric=\"correlation\")\n",
    "            corr = pd.DataFrame(corr, index=comps.columns, columns=comps.columns)\n",
    "            corr = corr.loc[good_labels,good_labels]\n",
    "            tc.pl.heatmap(corr,None,None,cmap=cmap_br,cmap_center=0, ax=axs[anno_i,3], value_cluster=value_cluster, group_cluster=group_cluster);\n",
    "\n",
    "            axs[anno_i,4].set_title(f'MMRp: {anno}')\n",
    "            comps = compost(pelka2mouse.query('TMMR == \"MMRp\"'), norm=norm, reads=reads, labels=anno, sample='PID')\n",
    "            corr = 1-tc.utils.cdist(comps.T,metric=\"correlation\")\n",
    "            corr = pd.DataFrame(corr, index=comps.columns, columns=comps.columns)\n",
    "            corr = corr.loc[good_labels,good_labels]\n",
    "            tc.pl.heatmap(corr,None,None,cmap=cmap_br,cmap_center=0, ax=axs[anno_i,4], value_cluster=value_cluster, group_cluster=group_cluster);\n",
    "\n",
    "\n",
    "        axs[-1,0].set_title('all mouse')\n",
    "        comps = compost(mouse_scrna, norm=norm, reads=reads, labels='labels', sample='SampleID')\n",
    "        corr = 1-tc.utils.cdist(comps.T,metric=\"correlation\")\n",
    "        corr = pd.DataFrame(corr, index=comps.columns, columns=comps.columns)\n",
    "        corr = corr.loc[good_labels,good_labels]\n",
    "        tc.pl.heatmap(corr,None,None,cmap=cmap_br,cmap_center=0, ax=axs[-1,0], value_cluster=value_cluster, group_cluster=group_cluster);\n",
    "\n",
    "        axs[-1,1].set_title('normal mouse')\n",
    "        comps = compost(mouse_scrna.query('State == \"normal\"'), norm=norm, reads=reads, labels='labels', sample='SampleID')\n",
    "        corr = 1-tc.utils.cdist(comps.T,metric=\"correlation\")\n",
    "        corr = pd.DataFrame(corr, index=comps.columns, columns=comps.columns)\n",
    "        corr = corr.loc[good_labels,good_labels]\n",
    "        tc.pl.heatmap(corr,None,None,cmap=cmap_br,cmap_center=0, ax=axs[-1,1], value_cluster=value_cluster, group_cluster=group_cluster);\n",
    "\n",
    "        axs[-1,2].set_title('not-normal mouse')\n",
    "        comps = compost(mouse_scrna.query('State != \"normal\"'), norm=norm, reads=reads, labels='labels', sample='SampleID')\n",
    "        corr = 1-tc.utils.cdist(comps.T,metric=\"correlation\")\n",
    "        corr = pd.DataFrame(corr, index=comps.columns, columns=comps.columns)\n",
    "        corr = corr.loc[good_labels,good_labels]\n",
    "        tc.pl.heatmap(corr,None,None,cmap=cmap_br,cmap_center=0, ax=axs[-1,2], value_cluster=value_cluster, group_cluster=group_cluster);\n",
    "\n",
    "        axs[-1,3].axis('off')\n",
    "\n",
    "        axs[-1,4].axis('off')\n",
    "\n",
    "        fig.savefig(f'{figures_folder}/human_sc_labels_associations_across_samples.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# program associations across samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epi_mouse = mouse_scrna.query('labels==\"Epi\"')\n",
    "epi_human = pelka2mouse[pelka2mouse.obs['clTopLevel'].isin(['Epi'])].copy()\n",
    "tc.tl.annotate(epi_human, epi_mouse, 'Epithelial_programs', result_key='Epithelial_programs', method='OT', bisections=4, assume_valid_counts=True,verbose=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cmap_br = LinearSegmentedColormap.from_list('cmap_br', ['#4d85b5', '#ffffff', '#ff1217'])\n",
    "\n",
    "progs = epi_mouse.obsm['Epithelial_programs'].columns\n",
    "good_progs = progs[progs.str.endswith(')')]\n",
    "\n",
    "# find clustering for mouse\n",
    "comps = compost(epi_mouse.query('State != \"normal\"'), 'clr', reads=False, labels='Epithelial_programs', sample='SampleID')\n",
    "corr = 1-tc.utils.cdist(comps.T,metric=\"correlation\")\n",
    "corr = pd.DataFrame(corr, index=comps.columns, columns=comps.columns)\n",
    "corr = corr.loc[good_progs,good_progs]\n",
    "Z = scipy.cluster.hierarchy.linkage(corr.T, method='average', metric='cosine')\n",
    "dn = scipy.cluster.hierarchy.dendrogram(Z, ax=None, orientation='right', color_threshold=0, above_threshold_color='tab:gray', no_plot=True)\n",
    "reordering = pd.Series(dn['ivl']).astype(np.int).to_numpy()\n",
    "good_progs = corr.iloc[reordering,reordering].columns.to_numpy()\n",
    "\n",
    "def compost(sub, norm, reads, labels='clTopLevel', sample='PID'):\n",
    "    print(tc.tl.get_compositions(sub,labels,sample,reads=reads).min()['Program 14 (Angiogenesis)'])\n",
    "    reads = reads == 'reads'\n",
    "    if norm == 'frac':\n",
    "        return tc.tl.get_compositions(sub,labels,sample,reads=reads)\n",
    "    elif norm == 'clr':\n",
    "        return tc.tl.get_contributions(sub,labels,sample,reads=reads, normalization='clr')\n",
    "    else:\n",
    "        raise ValueError()\n",
    "\n",
    "clustered = False\n",
    "\n",
    "fig,axs = tc.pl.subplots(7,1,axsize=[0.3*len(good_progs),0.3*len(good_progs)],x_padding=0.5,y_padding=2, sharey=True)\n",
    "\n",
    "value_cluster,group_cluster=clustered,clustered\n",
    "\n",
    "axs[0,0].set_title('all mouse')\n",
    "comps = compost(epi_mouse, 'clr', reads=False, labels='Epithelial_programs', sample='SampleID')\n",
    "corr = 1-tc.utils.cdist(comps.T,metric=\"correlation\")\n",
    "corr = pd.DataFrame(corr, index=comps.columns, columns=comps.columns)\n",
    "corr = corr.loc[good_progs,good_progs]\n",
    "tc.pl.heatmap(corr,None,None,cmap=cmap_br,cmap_center=0, ax=axs[0,0], value_cluster=value_cluster, group_cluster=group_cluster, colorbar=False);\n",
    "\n",
    "axs[0,1].set_title('normal mouse')\n",
    "comps = compost(epi_mouse.query('State == \"normal\"'), 'clr', reads=False, labels='Epithelial_programs', sample='SampleID')\n",
    "corr = 1-tc.utils.cdist(comps.T,metric=\"correlation\")\n",
    "corr = pd.DataFrame(corr, index=comps.columns, columns=comps.columns)\n",
    "corr = corr.loc[good_progs,good_progs]\n",
    "tc.pl.heatmap(corr,None,None,cmap=cmap_br,cmap_center=0, ax=axs[0,1], value_cluster=value_cluster, group_cluster=group_cluster, colorbar=False);\n",
    "\n",
    "axs[0,2].set_title('not-normal mouse')\n",
    "comps = compost(epi_mouse.query('State != \"normal\"'), 'clr', reads=False, labels='Epithelial_programs', sample='SampleID')\n",
    "corr = 1-tc.utils.cdist(comps.T,metric=\"correlation\")\n",
    "corr = pd.DataFrame(corr, index=comps.columns, columns=comps.columns)\n",
    "corr = corr.loc[good_progs,good_progs]\n",
    "tc.pl.heatmap(corr,None,None,cmap=cmap_br,cmap_center=0, ax=axs[0,2], value_cluster=value_cluster, group_cluster=group_cluster, colorbar=False);\n",
    "\n",
    "axs[0,3].set_title('all human')\n",
    "comps = compost(epi_human, 'clr', reads=False, labels='Epithelial_programs', sample='PID')\n",
    "corr = 1-tc.utils.cdist(comps.T,metric=\"correlation\")\n",
    "corr = pd.DataFrame(corr, index=comps.columns, columns=comps.columns)\n",
    "corr = corr.loc[good_progs,good_progs]\n",
    "tc.pl.heatmap(corr,None,None,cmap=cmap_br,cmap_center=0, ax=axs[0,3], value_cluster=value_cluster, group_cluster=group_cluster, colorbar=False);\n",
    "\n",
    "axs[0,4].set_title('normal human')\n",
    "comps = compost(epi_human.query('TMMR == \"normal\"'), 'clr', reads=False, labels='Epithelial_programs', sample='PID')\n",
    "corr = 1-tc.utils.cdist(comps.T,metric=\"correlation\")\n",
    "corr = pd.DataFrame(corr, index=comps.columns, columns=comps.columns)\n",
    "corr = corr.loc[good_progs,good_progs]\n",
    "tc.pl.heatmap(corr,None,None,cmap=cmap_br,cmap_center=0, ax=axs[0,4], value_cluster=value_cluster, group_cluster=group_cluster, colorbar=False);\n",
    "\n",
    "axs[0,5].set_title('MMRd human')\n",
    "comps = compost(epi_human.query('TMMR == \"MMRd\"'), 'clr', reads=False, labels='Epithelial_programs', sample='PID')\n",
    "corr = 1-tc.utils.cdist(comps.T,metric=\"correlation\")\n",
    "corr = pd.DataFrame(corr, index=comps.columns, columns=comps.columns)\n",
    "corr = corr.loc[good_progs,good_progs]\n",
    "tc.pl.heatmap(corr,None,None,cmap=cmap_br,cmap_center=0, ax=axs[0,5], value_cluster=value_cluster, group_cluster=group_cluster, colorbar=False);\n",
    "\n",
    "axs[0,6].set_title('MMRp only')\n",
    "comps = compost(epi_human.query('TMMR == \"MMRp\"'), 'clr', reads=False, labels='Epithelial_programs', sample='PID')\n",
    "corr = 1-tc.utils.cdist(comps.T,metric=\"correlation\")\n",
    "corr = pd.DataFrame(corr, index=comps.columns, columns=comps.columns)\n",
    "corr = corr.loc[good_progs,good_progs]\n",
    "tc.pl.heatmap(corr,None,None,cmap=cmap_br,cmap_center=0, ax=axs[0,6], value_cluster=value_cluster, group_cluster=group_cluster, );\n",
    "\n",
    "fig.savefig(f'{figures_folder}/human_sc_program_associations_across_samples.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smk_crc",
   "language": "python",
   "name": "smk_crc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
