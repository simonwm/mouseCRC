{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f250fd5-35ab-42ef-952e-19fb4c18d7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import scanpy as sc\n",
    "import seaborn as sns\n",
    "import tacco as tc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd73d30-9ffa-4dab-93af-4624349c1f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Make helper functions available: The notebook expects to be executed either in the sub-workflow directory or in the notebooks directory\n",
    "sys.path.insert(1, '../'), sys.path.insert(1, '../workflow/'); # prefer to look just one directory up\n",
    "import helper\n",
    "sys.path.pop(1), sys.path.pop(1);\n",
    "\n",
    "get_path = helper.get_paths('mouse_slideseq')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d89825-4382-4c41-9516-066c505de356",
   "metadata": {},
   "source": [
    "# settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb2c87b-b6c0-4b7b-800f-f2f5cd0dc83a",
   "metadata": {},
   "source": [
    "## visualization settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358e342a-4a40-4977-b37f-e196859d302c",
   "metadata": {},
   "outputs": [],
   "source": [
    "figures_folder = get_path('plots')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b701d19-4bc1-4a20-8ed1-8667473f0470",
   "metadata": {},
   "source": [
    "# Load mouse commot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a958f0ec-4e5c-45ff-a827-edf915fc5172",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_pathway = sc.read(f'{get_path(\"data\")}/mouse_slideseq_pathway.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c4faea-f7c3-43ea-aa65-9116ef5822ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_regions = adata_pathway.obs['region'].cat.categories\n",
    "ordered_regions = pd.Series(np.arange(len(all_regions))).astype(str).map({r.split(' ')[1]:r for r in adata_pathway.obs['region'].cat.categories}).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007dd7b5-1368-4b12-ace1-b703315b472f",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_pathway.obs['region'] = adata_pathway.obs['region'].astype(pd.CategoricalDtype(ordered_regions,ordered=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efa26a8-67d5-4b34-9c64-f3436f72d629",
   "metadata": {},
   "source": [
    "## Determine enrichments across samples using spatially separated patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fefae9-8582-40e9-a188-177c7755b5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "enrichments = {}\n",
    "\n",
    "for value_spec in ['pathway']:\n",
    "    value_adata = adata_pathway\n",
    "    \n",
    "    for group_key in ['State','region']:\n",
    "        value_spec_group_key = f'{value_spec}_{group_key}'\n",
    "        print(value_spec_group_key)\n",
    "        \n",
    "        enrichment_per_split_power = {}\n",
    "        \n",
    "        for split_power in range(6):\n",
    "            print('\\t',split_power)\n",
    "            tc.utils.split_spatial_samples(value_adata, buffer_thickness=400, split_scheme=(2,)*split_power, sample_key='SampleID', result_key='SampleID_split', check_splits=False)\n",
    "\n",
    "            # remove all split+group with less than 100 observations\n",
    "            value_adata.obs['SampleID_split+group'] = value_adata.obs['SampleID_split'].astype(str) + value_adata.obs[group_key].astype(str)\n",
    "            lowly_covered = value_adata.obs['SampleID_split+group'].value_counts()<100\n",
    "            lowly_covered = lowly_covered[lowly_covered].index\n",
    "            split_covered_group_key = f'split_covered_{group_key}'\n",
    "            value_adata.obs[split_covered_group_key] = value_adata.obs[group_key]\n",
    "            value_adata.obs.loc[value_adata.obs['SampleID_split+group'].isin(lowly_covered),split_covered_group_key] = None\n",
    "            \n",
    "            path_enr_sample_state = tc.tl.enrichments(value_adata,value_key=None,group_key=split_covered_group_key,sample_key='SampleID_split',reduction='mean',normalization=None,value_location='X',method='mwu',)\n",
    "            path_enr_sample_state.rename(columns={split_covered_group_key:group_key}, inplace=True)\n",
    "            path_enr_sample_state['split_power'] = split_power\n",
    "            enrichment_per_split_power[split_power] = path_enr_sample_state\n",
    "        \n",
    "        all_enrichments_per_split_power = pd.concat(enrichment_per_split_power.values())\n",
    "        all_enrichments_per_split_power[group_key] = all_enrichments_per_split_power[group_key].astype(pd.CategoricalDtype([c for c in value_adata.obs[group_key].cat.categories if c in all_enrichments_per_split_power[group_key].unique()], ordered=True))\n",
    "        all_enrichments_per_split_power['what'] = all_enrichments_per_split_power['value'].astype(str) + \" is \" + all_enrichments_per_split_power['enrichment'].astype(str) + \" in \" + all_enrichments_per_split_power[group_key].astype(str)\n",
    "        all_enrichments_per_split_power['$\\\\log_{10}(FDR)$'] = np.log10(all_enrichments_per_split_power['p_mwu_fdr_bh'])\n",
    "        all_enrichments_per_split_power[value_spec] = all_enrichments_per_split_power['value'].str.split('-',n=1).str[1]\n",
    "        all_enrichments_per_split_power['direction'] = all_enrichments_per_split_power['value'].str.split('-',n=1).str[0].map({'s':'sender','r':'receiver'})\n",
    "        \n",
    "        enrichments[value_spec_group_key] = all_enrichments_per_split_power"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5de14e8-3def-4ffa-9680-263443ac872d",
   "metadata": {},
   "source": [
    "## Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e44a4b-cd49-494c-a5ec-31fa8b903994",
   "metadata": {},
   "outputs": [],
   "source": [
    "interesting_regions = pd.Series(['2','6','11']).map({r.split(' ')[1]:r for r in ordered_regions}).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b54099-5751-4131-bd30-6408b7b6054e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dependency_on_split_power(all_enrichments_per_split_power, value_spec, group_key, n_pathways=20, n_pathways_per_ax=4, only_groups=None):\n",
    "\n",
    "    if only_groups is None:\n",
    "        all_groups = adata_pathway.obs[group_key].cat.categories\n",
    "    else:\n",
    "        all_groups = only_groups\n",
    "    n_ax_per_row = (n_pathways+1)//n_pathways_per_ax\n",
    "    fig,axs = tc.pl.subplots(n_ax_per_row,len(all_groups), axsize=(2,2), y_padding=1.0, x_padding=2.0, sharex=False, sharey=True, dpi=72)\n",
    "    for i_group,_group in enumerate(all_groups):\n",
    "        sub_enrichments = all_enrichments_per_split_power[all_enrichments_per_split_power[group_key].isin([_group])&(all_enrichments_per_split_power['enrichment']=='enriched')].reset_index().copy()\n",
    "        top_pathways = sub_enrichments[(sub_enrichments['split_power'] == 2)&(sub_enrichments['p_mwu_fdr_bh']<0.05)].sort_values('p_mwu_fdr_bh').drop_duplicates(value_spec)[value_spec].head(n_pathways).to_numpy()\n",
    "        for _i,_top_pathways in enumerate([top_pathways[p:p+n_pathways_per_ax] for p in range(0, len(top_pathways), n_pathways_per_ax)]):\n",
    "            _sub_enrichments = sub_enrichments[sub_enrichments[value_spec].isin(_top_pathways)].reset_index().copy()\n",
    "            _sub_enrichments[value_spec] = _sub_enrichments[value_spec].astype(pd.CategoricalDtype(categories=_top_pathways, ordered=True))\n",
    "            _sub_enrichments['value'] = _sub_enrichments['value'].astype(str).astype('category')\n",
    "            ax = axs[i_group,_i]\n",
    "            ax.set_title(_group)\n",
    "            ax.hlines(np.log10(0.05),0,1,transform=ax.get_yaxis_transform(), color='#AAAAAA')\n",
    "            sax = sns.lineplot(data=_sub_enrichments, x='split_power', y='$\\\\log_{10}(FDR)$', hue=value_spec, style='direction', ax=ax)\n",
    "            sax.set_xticks([0,1,2,3,4,5])\n",
    "            sax.set_xticklabels([0,1,2,3,4,5])\n",
    "            if len(_sub_enrichments) > 0:\n",
    "                sns.move_legend(sax, \"upper left\", bbox_to_anchor=(1.05, 1), ncol=1, title=None, frameon=False)\n",
    "        for _i2 in range(_i+1,n_ax_per_row):\n",
    "            ax = axs[i_group,_i2]\n",
    "            ax.set_axis_off()\n",
    "\n",
    "    return fig\n",
    "\n",
    "for value_spec in ['pathway']:\n",
    "    for group_key in ['State','region']:\n",
    "        value_spec_group_key = f'{value_spec}_{group_key}'\n",
    "        print(value_spec_group_key)\n",
    "        \n",
    "        only_groups = None if group_key == 'State' else interesting_regions\n",
    "        fig = plot_dependency_on_split_power(enrichments[value_spec_group_key], value_spec=value_spec, group_key=group_key, n_pathways=5, n_pathways_per_ax=5, only_groups=only_groups)\n",
    "\n",
    "        fig.savefig(f'{figures_folder}/spatial_split_bidirectional_communication_{value_spec}_per_{group_key}.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec59b0cc-f349-4abd-a6de-d95d1728d217",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for value_spec in ['pathway']:\n",
    "    for group_key in ['State','region']:\n",
    "        value_spec_group_key = f'{value_spec}_{group_key}'\n",
    "        print(value_spec_group_key)\n",
    "\n",
    "        sub_enrichments = enrichments[value_spec_group_key][enrichments[value_spec_group_key]['split_power']==2].copy()\n",
    "        \n",
    "        n_pathways = 100\n",
    "        top_pathways = sub_enrichments[sub_enrichments['p_mwu_fdr_bh']<0.05].sort_values('p_mwu_fdr_bh').drop_duplicates(value_spec)[value_spec].head(n_pathways).to_numpy()\n",
    "        sub_enrichments = sub_enrichments[sub_enrichments[value_spec].isin(top_pathways)].reset_index().copy()\n",
    "        sub_enrichments[value_spec] = sub_enrichments[value_spec].astype(pd.CategoricalDtype(categories=reversed(top_pathways), ordered=True))\n",
    "        \n",
    "        senders_significances = sub_enrichments[sub_enrichments['direction']=='sender']\n",
    "        receiver_significances = sub_enrichments[sub_enrichments['direction']=='receiver']\n",
    "        \n",
    "        fig,axs = tc.pl.subplots(2,1, axsize=(len(sub_enrichments[group_key].cat.categories)*0.7,len(top_pathways)*0.25), x_padding=3.0, dpi=72)\n",
    "        tc.pl.significances(senders_significances, p_key='p_mwu_fdr_bh', value_key=value_spec, group_key=group_key, ax=axs[0,0]); axs[0,0].set_title('sender')\n",
    "        tc.pl.significances(receiver_significances, p_key='p_mwu_fdr_bh', value_key=value_spec, group_key=group_key, ax=axs[0,1]); axs[0,1].set_title('receiver')\n",
    "        \n",
    "        fig.savefig(f'{figures_folder}/spatial_split_bidirectional_communication_{value_spec}_per_{group_key}_heatmap.pdf',bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9373d384-8219-4b4c-975c-be71a61e841c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_enrichments(significances, group_key='State', value_key='pathway'):\n",
    "    small_value = 1e-300\n",
    "    pmax = 0.05\n",
    "    min_log = -np.log(pmax)\n",
    "\n",
    "    enr_e = pd.pivot(significances[significances['enrichment']=='enriched'], value_key, group_key, 'p_mwu_fdr_bh')\n",
    "    enr_p = pd.pivot(significances[significances['enrichment']!='enriched'], value_key, group_key, 'p_mwu_fdr_bh')\n",
    "\n",
    "    enr_e = np.maximum(enr_e,small_value)\n",
    "    enr_p = np.maximum(enr_p,small_value)\n",
    "\n",
    "    enr_p = enr_p.reindex_like(enr_e)\n",
    "\n",
    "    enr = pd.DataFrame(np.where(enr_e < enr_p, -np.log10(enr_e), np.log10(enr_p)),index=enr_e.index,columns=enr_e.columns)\n",
    "    \n",
    "    return enr\n",
    "\n",
    "def enrichment_scatter_plot(merged_enrichments, ax, pathways_to_annotate=None, where=None):\n",
    "    enriched_color = (1.0, 0.07058823529411765, 0.09019607843137255)\n",
    "    depleted_color = (0.30196078431372547, 0.5215686274509804, 0.7098039215686275)\n",
    "    null_color = (0.9,0.9,0.9)\n",
    "    slightly_weight = 0.5\n",
    "    slightly_enriched_color, slightly_depleted_color = tc.pl.mix_base_colors(\n",
    "        np.array([[slightly_weight,1-slightly_weight,0.0],[0.0,1-slightly_weight,slightly_weight],]),\n",
    "        np.array([list(enriched_color),list(null_color),list(depleted_color)])\n",
    "    )\n",
    "    enriched_color, depleted_color, slightly_enriched_color, slightly_depleted_color, null_color = [matplotlib.colors.to_hex(c) for c in [enriched_color, depleted_color, slightly_enriched_color, slightly_depleted_color, null_color]]\n",
    "    merged_enrichments['sender_enriched'] = merged_enrichments['sender'] > -np.log10(0.05)\n",
    "    merged_enrichments['sender_depleted'] = merged_enrichments['sender'] <  np.log10(0.05)\n",
    "    merged_enrichments['receiver_enriched'] = merged_enrichments['receiver'] > -np.log10(0.05)\n",
    "    merged_enrichments['receiver_depleted'] = merged_enrichments['receiver'] <  np.log10(0.05)\n",
    "    merged_enrichments['color'] = np.where(merged_enrichments['sender_enriched'] & merged_enrichments['receiver_enriched'], enriched_color,\n",
    "                                  np.where(merged_enrichments['sender_depleted'] & merged_enrichments['receiver_depleted'], depleted_color,\n",
    "                                  np.where(merged_enrichments['sender_enriched'] | merged_enrichments['receiver_enriched'], slightly_enriched_color,\n",
    "                                  np.where(merged_enrichments['sender_depleted'] | merged_enrichments['receiver_depleted'], slightly_depleted_color,\n",
    "                                           null_color\n",
    "                                          ))))\n",
    "\n",
    "    sub = merged_enrichments#[merged_enrichments['receiver_significant']]\n",
    "\n",
    "    ax.hlines( np.log10(0.05),0,1,transform=ax.get_yaxis_transform(), color='#CCC', zorder=-1)\n",
    "    ax.hlines(-np.log10(0.05),0,1,transform=ax.get_yaxis_transform(), color='#CCC', zorder=-1)\n",
    "    ax.vlines( np.log10(0.05),0,1,transform=ax.get_xaxis_transform(), color='#CCC', zorder=-1)\n",
    "    ax.vlines(-np.log10(0.05),0,1,transform=ax.get_xaxis_transform(), color='#CCC', zorder=-1)\n",
    "    ax.scatter(sub['sender'], sub['receiver'], c=sub['color'])\n",
    "    maxlim = max([abs(i) for i in [*ax.get_xlim(),*ax.get_ylim()]])\n",
    "    ax.set_xlim(-maxlim, maxlim)\n",
    "    ax.set_ylim(-maxlim, maxlim)\n",
    "    ax.set_xticks([v for v in ax.get_xticks() if v!=0]) # remove tick at maximum insignificance\n",
    "    x_tick_labels = [f'$10^{{-{int(abs(v))}}}$' for v in ax.get_xticks()]\n",
    "    ax.set_xticklabels(x_tick_labels)\n",
    "    ax.set_yticks([v for v in ax.get_yticks() if v!=0])\n",
    "    y_tick_labels = [f'$10^{{-{int(abs(v))}}}$' for v in ax.get_yticks()]\n",
    "    ax.set_yticklabels(y_tick_labels)\n",
    "    ax.set_xlim(-maxlim, maxlim) # reset the range as the xticks which one sees are not identical to the ones delivered by get_xticks()...\n",
    "    ax.set_ylim(-maxlim, maxlim)\n",
    "\n",
    "    if where is None:\n",
    "        main_text = 'enrichment'\n",
    "        enriched_text = 'in premalignant'\n",
    "        depleted_text = 'in normal'\n",
    "    else:\n",
    "        main_text = f'in {where}'\n",
    "        enriched_text = 'enriched'\n",
    "        depleted_text = 'depleted'\n",
    "    \n",
    "    ax.text(0.5,-0.20,f'sender {main_text} (FDR)',horizontalalignment='center',verticalalignment='top',transform=ax.transAxes)\n",
    "    ax.text(1.00,-0.13,enriched_text,horizontalalignment='right',verticalalignment='top',transform=ax.transAxes)\n",
    "    ax.text(0.00,-0.13,depleted_text,horizontalalignment='left',verticalalignment='top',transform=ax.transAxes)\n",
    "    ax.annotate(\"\", xy=(-0.05,-0.11), xytext=(0.40,-0.11), arrowprops=dict(arrowstyle=\"->\"),xycoords='axes fraction',textcoords='axes fraction')\n",
    "    ax.annotate(\"\", xy=(1.05,-0.11), xytext=(0.60,-0.11), arrowprops=dict(arrowstyle=\"->\"),xycoords='axes fraction',textcoords='axes fraction')\n",
    "\n",
    "    ax.text(-0.25,0.5,f'reciever {main_text} (FDR)',horizontalalignment='right',verticalalignment='center',transform=ax.transAxes,rotation='vertical')\n",
    "    ax.text(-0.18,1.00,enriched_text,horizontalalignment='right',verticalalignment='top',transform=ax.transAxes,rotation='vertical')\n",
    "    ax.text(-0.18,0.00,depleted_text,horizontalalignment='right',verticalalignment='bottom',transform=ax.transAxes,rotation='vertical')\n",
    "    ax.annotate(\"\", xy=(-0.16,-0.05), xytext=(-0.16,0.40), arrowprops=dict(arrowstyle=\"->\"),xycoords='axes fraction',textcoords='axes fraction')\n",
    "    ax.annotate(\"\", xy=(-0.16,1.05), xytext=(-0.16,0.60), arrowprops=dict(arrowstyle=\"->\"),xycoords='axes fraction',textcoords='axes fraction')\n",
    "\n",
    "    if pathways_to_annotate is not None:\n",
    "        nps = len(pathways_to_annotate)\n",
    "        for pathway,radius,theta in zip(pathways_to_annotate['pathways'],pathways_to_annotate['radii'],pathways_to_annotate['thetas']):\n",
    "            x_y_data = sub.loc[pathway,['sender','receiver']]\n",
    "            x_y_text_delta = radius * np.array([np.cos(theta),np.sin(theta)])\n",
    "            ax.annotate(pathway,x_y_data,xytext=x_y_text_delta,textcoords='offset points',arrowprops=dict(arrowstyle=\"-\"),horizontalalignment='center',verticalalignment='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06af4cca-fd23-4ff3-9f2b-4b60615280d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def padN(iterable,N):\n",
    "    iterated = [i for i in iterable]\n",
    "    return [*iterated,*[None for i in range(len(iterated),N)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d80b180-13a7-4890-bd36-dc2de8eba142",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_enriched = {}\n",
    "for value_spec_group_key, enr in enrichments.items():\n",
    "    value_spec,group_key = value_spec_group_key.split('_')\n",
    "    interesting_groups = interesting_regions if group_key == 'region' else ['normal','premalignant']\n",
    "    top_enriched[value_spec_group_key] = pd.DataFrame({r: padN(enrichments[value_spec_group_key][\n",
    "        enrichments[value_spec_group_key][group_key].isin([r]) & \n",
    "        enrichments[value_spec_group_key]['split_power'].isin([2]) & \n",
    "        enrichments[value_spec_group_key]['enrichment'].isin(['enriched']) & \n",
    "        (enrichments[value_spec_group_key]['p_mwu_fdr_bh'] <= 0.05)\n",
    "    ].sort_values('p_mwu_fdr_bh').drop_duplicates(value_spec)[value_spec].head(5).to_numpy(),5) for r in interesting_groups})\n",
    "top_enriched = pd.concat(top_enriched, axis=1)\n",
    "top_enriched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e0634b-e886-4e55-9f9f-1603f32a1b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_depleted = {}\n",
    "for value_spec_group_key, enr in enrichments.items():\n",
    "    value_spec,group_key = value_spec_group_key.split('_')\n",
    "    interesting_groups = interesting_regions if group_key == 'region' else ['normal','premalignant']\n",
    "    top_depleted[value_spec_group_key] = pd.DataFrame({r: padN(enrichments[value_spec_group_key][\n",
    "        enrichments[value_spec_group_key][group_key].isin([r]) & \n",
    "        enrichments[value_spec_group_key]['split_power'].isin([2]) & \n",
    "        enrichments[value_spec_group_key]['enrichment'].isin(['purified']) & \n",
    "        (enrichments[value_spec_group_key]['p_mwu_fdr_bh'] <= 0.05)\n",
    "    ].sort_values('p_mwu_fdr_bh').drop_duplicates(value_spec)[value_spec].head(5).to_numpy(),5) for r in interesting_groups})\n",
    "top_depleted = pd.concat(top_depleted, axis=1)\n",
    "top_depleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d50875-a3b2-46cf-be17-a739a3a81746",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for value_spec in ['pathway']:\n",
    "    for group_key in ['State','region']:\n",
    "        value_spec_group_key = f'{value_spec}_{group_key}'\n",
    "        print(value_spec_group_key)\n",
    "\n",
    "        sub_enrichments = enrichments[value_spec_group_key][enrichments[value_spec_group_key]['split_power']==2].copy()\n",
    "        senders_significances = sub_enrichments[sub_enrichments['direction']=='sender']\n",
    "        receiver_significances = sub_enrichments[sub_enrichments['direction']=='receiver']\n",
    "\n",
    "        if group_key == 'State':\n",
    "            merged_enrichments = pd.DataFrame({\n",
    "                'sender': merge_enrichments(senders_significances, value_key=value_spec)['premalignant'],\n",
    "                'receiver': merge_enrichments(receiver_significances, value_key=value_spec)['premalignant'],\n",
    "            })\n",
    "\n",
    "            pathways_to_annotate = None\n",
    "            if value_spec == 'pathway':\n",
    "                pathways_to_annotate = pd.DataFrame({\n",
    "                    'pathways':['CD137','RANKL','TNF','CSF', 'MK','GCG','AGT','NPY',],\n",
    "                    'radii':   [     30,     30,   20,   20,   20,   18,   20,   20,],\n",
    "                    'thetas':  [   1.00,   1.00,-0.25,-0.25,-0.50, 1.50, 1.75, 0.75,],\n",
    "                })\n",
    "                pathways_to_annotate['thetas'] *= np.pi\n",
    "\n",
    "            fig,axs = tc.pl.subplots(axsize=(3,3))\n",
    "\n",
    "            enrichment_scatter_plot(merged_enrichments, ax=axs[0,0], pathways_to_annotate=pathways_to_annotate)\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            all_regions = interesting_regions\n",
    "            fig,axs = tc.pl.subplots(len(all_regions),axsize=(3,3),x_padding=1.2, dpi=72)\n",
    "            for ir,region in enumerate(all_regions):\n",
    "                region_short = region.split(' ',2)\n",
    "                region_short = region_short[0] + ' ' + region_short[1]\n",
    "\n",
    "                merged_enrichments = pd.DataFrame({\n",
    "                    'sender': merge_enrichments(senders_significances, group_key, value_key=value_spec)[region],\n",
    "                    'receiver': merge_enrichments(receiver_significances, group_key, value_key=value_spec)[region],\n",
    "                })\n",
    "\n",
    "                pathways_to_annotate = None\n",
    "                if value_spec == 'pathway':\n",
    "                    if region_short == 'Region 2':\n",
    "                        pathways_to_annotate = pd.DataFrame({\n",
    "                         'pathways':['ANGPTL','PTN','PSAP','TAC','FGF','GUCA','GRN','GALECTIN','NRG','CX3C',],\n",
    "                         'radii':   [      35,   23,    30,   18,   20,    30,   20,        23,   25,    30,],\n",
    "                         'thetas':  [   -1.00,-1.00,  0.00, 1.50, 0.00,  0.00,-0.50,      0.50, 0.00,  1.00,],\n",
    "                        })\n",
    "                        pathways_to_annotate['thetas'] *= np.pi\n",
    "                    elif region_short == 'Region 6':\n",
    "                        pathways_to_annotate = pd.DataFrame({\n",
    "                         'pathways':['CD137','TNF', 'MK','GCG', 'HH','TRAIL',],\n",
    "                         'radii':   [     30,   23,   20,   18,   20,     30,],\n",
    "                         'thetas':  [   0.00, 0.00, 0.00, 1.50, 0.00,   0.00,],\n",
    "                        })\n",
    "                        pathways_to_annotate['thetas'] *= np.pi\n",
    "                    else: # Region 11\n",
    "                        pathways_to_annotate = pd.DataFrame({\n",
    "                         'pathways':['OSM','VEGI', 'CD137','PTN', 'MK','GUCA','GCG','VIP',],\n",
    "                         'radii':   [   30,    23,      20,   23,   20,    30,   18,   18,],\n",
    "                         'thetas':  [ 0.00,  0.00,   -0.50, 1.00, 0.00,  1.00, 0.50, 1.50,],\n",
    "                        })\n",
    "                        pathways_to_annotate['thetas'] *= np.pi\n",
    "\n",
    "                enrichment_scatter_plot(merged_enrichments, ax=axs[0,ir], pathways_to_annotate=pathways_to_annotate, where=region_short)\n",
    "\n",
    "        fig.savefig(f'{figures_folder}/spatial_split_bidirectional_communication_{value_spec}_per_{group_key}_scatter.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9c8a96-925f-4b22-b692-124730c62e7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
